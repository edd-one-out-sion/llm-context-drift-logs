Session 6 — Alignment Science Fit
This repository contains high-density human–LLM interaction logs capturing real-time context-drift and policy-layer interference.
Session 6 provides a rare ground-truth case where a human operator detected hallucinated attribution and semantic inversion live.
The failure was not simple memory loss but policy-amplified reference corruption.
RMS (Root Meltdown Segments) are mapped to exact message IDs in mrs/SESSION_6_rms_coordinates.md.
Raw evidence exists as SESSION_6_dom.html and SESSION_6_raw.json (hash-preserved, offline-stored).
This allows mechanistic interpretability and alignment science to study how policy layers distort internal reference resolution.
The failure mode matches Anthropic’s concern about deceptive or unstable behavior emerging under load.
Unlike synthetic benchmarks, this is a naturalistic, high-stakes interaction.
The dataset enables empirical testing of scalable oversight and misattribution detection.
We are seeking responsible research engagement, not public disclosure.
